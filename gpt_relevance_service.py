#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPTé–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹
ä»•æ§˜æ›¸ bungo_update_spec_draft01.md S5ç«  GPTé–¢é€£åº¦åˆ¤å®šãƒ»APIåŒ–ã«åŸºã¥ãå®Ÿè£…

åœ°åãƒ»æ–‡è„ˆãƒ»ä½œå“ã®é–¢é€£åº¦ã‚’GPTã§åˆ¤å®šã—ã€relevanceâ‰¥0.8ã®ã¿å¯è¦–åŒ–å¯¾è±¡ã¨ã™ã‚‹
"""

import os
import time
import json
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logging.warning("OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚GPTé–¢é€£åº¦åˆ¤å®šã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")


@dataclass
class RelevanceRequest:
    """é–¢é€£åº¦åˆ¤å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    place_name: str
    sentence: str
    work_title: str
    author_name: str
    context: Optional[str] = None
    

@dataclass
class RelevanceResponse:
    """é–¢é€£åº¦åˆ¤å®šãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    relevance_score: float
    is_relevant: bool
    reasoning: str
    execution_time: float
    

class GPTRelevanceService:
    """GPTé–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, api_key: str = None, relevance_threshold: float = 0.8):
        """
        Args:
            api_key: OpenAI API ã‚­ãƒ¼
            relevance_threshold: é–¢é€£åº¦é–¾å€¤ï¼ˆã“ã®å€¤ä»¥ä¸Šã‚’ã€Œé–¢é€£ã‚ã‚Šã€ã¨åˆ¤å®šï¼‰
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.relevance_threshold = relevance_threshold
        self.logger = logging.getLogger(__name__)
        
        if not OPENAI_AVAILABLE:
            self.client = None
            self.logger.warning("âš ï¸ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç„¡åŠ¹ - é–¢é€£åº¦åˆ¤å®šã¯å¸¸ã«1.0ã‚’è¿”ã—ã¾ã™")
        elif not self.api_key:
            self.client = None
            self.logger.warning("âš ï¸ OpenAI APIã‚­ãƒ¼æœªè¨­å®š - é–¢é€£åº¦åˆ¤å®šã¯å¸¸ã«1.0ã‚’è¿”ã—ã¾ã™")
        else:
            self.client = OpenAI(api_key=self.api_key)
            self.logger.info("âœ… GPTé–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    def judge_relevance(self, request: RelevanceRequest) -> RelevanceResponse:
        """
        å˜ä¸€ã®åœ°åãƒ»æ–‡è„ˆãƒšã‚¢ã®é–¢é€£åº¦ã‚’åˆ¤å®š
        
        Args:
            request: é–¢é€£åº¦åˆ¤å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            
        Returns:
            é–¢é€£åº¦åˆ¤å®šçµæœ
        """
        start_time = time.time()
        
        if not self.client:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: GPTç„¡åŠ¹æ™‚ã¯å¸¸ã«é–¢é€£ã‚ã‚Šã¨ã—ã¦è¿”ã™
            return RelevanceResponse(
                relevance_score=1.0,
                is_relevant=True,
                reasoning="GPTåˆ¤å®šç„¡åŠ¹ã®ãŸã‚ã€ã™ã¹ã¦é–¢é€£ã‚ã‚Šã¨ã—ã¦å‡¦ç†",
                execution_time=time.time() - start_time
            )
        
        try:
            prompt = self._create_relevance_prompt(request)
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ã‚ãªãŸã¯æ–‡å­¦ä½œå“ã¨åœ°åã®é–¢é€£åº¦ã‚’åˆ¤å®šã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
                                  "ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã€åœ°åãŒä½œå“ã«å®Ÿéš›ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’0.0-1.0ã®æ•°å€¤ã§åˆ¤å®šã—ã¦ãã ã•ã„ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.1  # ä¸€è²«ã—ãŸåˆ¤å®šã®ãŸã‚ä½ã‚ã«è¨­å®š
            )
            
            response_text = response.choices[0].message.content
            score, reasoning = self._parse_gpt_response(response_text)
            
            execution_time = time.time() - start_time
            
            return RelevanceResponse(
                relevance_score=score,
                is_relevant=score >= self.relevance_threshold,
                reasoning=reasoning,
                execution_time=execution_time
            )
            
        except Exception as e:
            self.logger.error(f"âŒ GPTé–¢é€£åº¦åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            execution_time = time.time() - start_time
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’è¿”ã™
            return RelevanceResponse(
                relevance_score=0.5,
                is_relevant=False,
                reasoning=f"åˆ¤å®šã‚¨ãƒ©ãƒ¼ã®ãŸã‚ä¸­ç«‹å€¤: {str(e)}",
                execution_time=execution_time
            )
    
    def judge_relevance_batch(self, requests: List[RelevanceRequest]) -> List[RelevanceResponse]:
        """
        è¤‡æ•°ã®åœ°åãƒ»æ–‡è„ˆãƒšã‚¢ã‚’ä¸€æ‹¬ã§é–¢é€£åº¦åˆ¤å®š
        
        Args:
            requests: é–¢é€£åº¦åˆ¤å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            
        Returns:
            é–¢é€£åº¦åˆ¤å®šçµæœã®ãƒªã‚¹ãƒˆ
        """
        self.logger.info(f"ğŸ” ä¸€æ‹¬é–¢é€£åº¦åˆ¤å®šé–‹å§‹: {len(requests)}ä»¶")
        
        results = []
        for i, request in enumerate(requests):
            self.logger.debug(f"åˆ¤å®šä¸­: {i+1}/{len(requests)} - {request.place_name}")
            
            result = self.judge_relevance(request)
            results.append(result)
            
            # APIåˆ¶é™å¯¾ç­–
            if self.client and i < len(requests) - 1:
                time.sleep(0.1)
        
        relevant_count = sum(1 for r in results if r.is_relevant)
        self.logger.info(f"âœ… ä¸€æ‹¬é–¢é€£åº¦åˆ¤å®šå®Œäº†: {relevant_count}/{len(results)}ä»¶ãŒé–¢é€£ã‚ã‚Š")
        
        return results
    
    def filter_relevant_places(self, places_data: List[Dict]) -> List[Dict]:
        """
        åœ°åãƒ‡ãƒ¼ã‚¿ã‚’é–¢é€£åº¦ã§çµã‚Šè¾¼ã¿
        
        Args:
            places_data: åœ°åãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            é–¢é€£åº¦â‰¥é–¾å€¤ã®åœ°åãƒ‡ãƒ¼ã‚¿ã®ã¿
        """
        if not places_data:
            return []
        
        self.logger.info(f"ğŸ¯ é–¢é€£åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹: {len(places_data)}ä»¶")
        
        requests = []
        for place in places_data:
            request = RelevanceRequest(
                place_name=place.get('place_name', ''),
                sentence=place.get('sentence', ''),
                work_title=place.get('work_title', ''),
                author_name=place.get('author_name', ''),
                context=place.get('before_text', '') + place.get('after_text', '')
            )
            requests.append(request)
        
        responses = self.judge_relevance_batch(requests)
        
        # é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ ã—ã¦çµã‚Šè¾¼ã¿
        relevant_places = []
        for place, response in zip(places_data, responses):
            place_with_score = place.copy()
            place_with_score['relevance_score'] = response.relevance_score
            place_with_score['relevance_reasoning'] = response.reasoning
            
            if response.is_relevant:
                relevant_places.append(place_with_score)
        
        self.logger.info(f"âœ… é–¢é€£åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(relevant_places)}/{len(places_data)}ä»¶ãŒé–¢é€£ã‚ã‚Š")
        
        return relevant_places
    
    def _create_relevance_prompt(self, request: RelevanceRequest) -> str:
        """é–¢é€£åº¦åˆ¤å®šç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®æƒ…å ±ã‚’åˆ†æã—ã€åœ°åãŒæ–‡å­¦ä½œå“ã«å®Ÿéš›ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€åˆ¤å®šå¯¾è±¡ã€‘
ä½œè€…: {request.author_name}
ä½œå“: {request.work_title}
åœ°å: {request.place_name}
è©²å½“æ–‡: {request.sentence}
"""
        
        if request.context:
            prompt += f"æ–‡è„ˆ: {request.context}\n"
        
        prompt += """
ã€åˆ¤å®šåŸºæº–ã€‘
1.0: ä½œå“ã®èˆå°ãƒ»è¨­å®šã¨ã—ã¦æ˜ç¢ºã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹
0.9: ä½œå“ã«é‡è¦ãªå½¹å‰²ã§ç™»å ´ã—ã¦ã„ã‚‹
0.8: ä½œå“ã«å…·ä½“çš„ã«è¨€åŠã•ã‚Œã¦ã„ã‚‹
0.7: ä½œå“ã«é–¢é€£æ€§ãŒã‚ã‚‹ãŒé–“æ¥çš„
0.6: ä½œå“ã¨ã®é–¢é€£æ€§ãŒæ›–æ˜§
0.5: é–¢é€£æ€§ãŒä¸æ˜ç¢º
0.4: é–¢é€£æ€§ãŒä½ã„
0.3: ã»ã¼é–¢é€£æ€§ãŒãªã„
0.2: é–¢é€£æ€§ãŒãªã„
0.1-0.0: å…¨ãé–¢é€£æ€§ãŒãªã„

ã€å‡ºåŠ›å½¢å¼ã€‘
ã‚¹ã‚³ã‚¢: 0.0-1.0ã®æ•°å€¤
ç†ç”±: åˆ¤å®šç†ç”±ã‚’ç°¡æ½”ã«èª¬æ˜

ä¾‹:
ã‚¹ã‚³ã‚¢: 0.9
ç†ç”±: ä¸»äººå…¬ãŒå®Ÿéš›ã«è¨ªã‚ŒãŸèˆå°ã¨ã—ã¦ä½œå“ä¸­ã§è©³ç´°ã«æå†™ã•ã‚Œã¦ã„ã‚‹ãŸã‚
"""
        
        return prompt
    
    def _parse_gpt_response(self, response_text: str) -> Tuple[float, str]:
        """GPTãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            lines = response_text.strip().split('\n')
            score = 0.5
            reasoning = "è§£æå¤±æ•—"
            
            for line in lines:
                line = line.strip()
                if line.startswith('ã‚¹ã‚³ã‚¢:') or line.startswith('Score:'):
                    # ã‚¹ã‚³ã‚¢æŠ½å‡º
                    score_text = line.split(':', 1)[1].strip()
                    score = float(score_text)
                    score = max(0.0, min(1.0, score))  # 0.0-1.0ã®ç¯„å›²ã«ã‚¯ãƒ©ãƒ³ãƒ—
                elif line.startswith('ç†ç”±:') or line.startswith('Reason:'):
                    # ç†ç”±æŠ½å‡º
                    reasoning = line.split(':', 1)[1].strip()
            
            return score, reasoning
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ GPTãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æå¤±æ•—: {e}")
            return 0.5, f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def get_stats(self, places_data: List[Dict]) -> Dict:
        """é–¢é€£åº¦çµ±è¨ˆå–å¾—"""
        if not places_data:
            return {
                'total_places': 0,
                'relevant_places': 0,
                'relevance_rate': 0.0,
                'avg_relevance_score': 0.0
            }
        
        total_places = len(places_data)
        relevant_places = sum(1 for p in places_data 
                            if p.get('relevance_score', 0) >= self.relevance_threshold)
        
        scores = [p.get('relevance_score', 0) for p in places_data if 'relevance_score' in p]
        avg_score = sum(scores) / len(scores) if scores else 0.0
        
        return {
            'total_places': total_places,
            'relevant_places': relevant_places,
            'relevance_rate': (relevant_places / total_places * 100) if total_places > 0 else 0.0,
            'avg_relevance_score': avg_score,
            'threshold': self.relevance_threshold
        }


def test_relevance_service():
    """é–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª GPTé–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_requests = [
        RelevanceRequest(
            place_name="æ¾å±±å¸‚",
            sentence="å››å›½ã¯æ¾å±±ã®ä¸­å­¦æ ¡ã«æ•°å­¦ã®æ•™å¸«ã¨ã—ã¦èµ´ä»»ã™ã‚‹ã“ã¨ã«ãªã£ãŸã€‚",
            work_title="åŠã£ã¡ã‚ƒã‚“",
            author_name="å¤ç›®æ¼±çŸ³"
        ),
        RelevanceRequest(
            place_name="æ±äº¬",
            sentence="æ±äº¬",
            work_title="è‰æ•",
            author_name="å¤ç›®æ¼±çŸ³"
        ),
        RelevanceRequest(
            place_name="ã ã‚“ã ã‚‰",
            sentence="ã ã‚“ã ã‚‰",
            work_title="è‰æ•", 
            author_name="å¤ç›®æ¼±çŸ³"
        )
    ]
    
    service = GPTRelevanceService()
    
    print(f"\nğŸ” å˜ç™ºãƒ†ã‚¹ãƒˆ:")
    for i, req in enumerate(test_requests, 1):
        response = service.judge_relevance(req)
        print(f"{i}. åœ°åã€Œ{req.place_name}ã€")
        print(f"   ã‚¹ã‚³ã‚¢: {response.relevance_score:.2f}")
        print(f"   é–¢é€£: {'âœ…' if response.is_relevant else 'âŒ'}")
        print(f"   ç†ç”±: {response.reasoning}")
        print(f"   æ™‚é–“: {response.execution_time:.3f}ç§’")
        print()
    
    print(f"ğŸ” ä¸€æ‹¬ãƒ†ã‚¹ãƒˆ:")
    responses = service.judge_relevance_batch(test_requests)
    relevant_count = sum(1 for r in responses if r.is_relevant)
    print(f"é–¢é€£ã‚ã‚Š: {relevant_count}/{len(responses)}ä»¶")
    
    # çµ±è¨ˆãƒ†ã‚¹ãƒˆ
    test_places = [
        {
            'place_name': req.place_name,
            'relevance_score': resp.relevance_score
        }
        for req, resp in zip(test_requests, responses)
    ]
    
    stats = service.get_stats(test_places)
    print(f"\nğŸ“Š çµ±è¨ˆ:")
    print(f"ç·åœ°åæ•°: {stats['total_places']}")
    print(f"é–¢é€£åœ°åæ•°: {stats['relevant_places']}")
    print(f"é–¢é€£åº¦ç‡: {stats['relevance_rate']:.1f}%")
    print(f"å¹³å‡ã‚¹ã‚³ã‚¢: {stats['avg_relevance_score']:.2f}")


if __name__ == "__main__":
    test_relevance_service() 