#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  REST API
ä»•æ§˜æ›¸ bungo_update_spec_draft01.md S5ç«  APIåŒ–ã«åŸºã¥ãFastAPIå®Ÿè£…

OpenAPIä»•æ§˜: s5_openapi_spec.yaml
"""

import os
import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any

try:
    from fastapi import FastAPI, HTTPException, Query, Path, Body, Depends
    from fastapi.responses import JSONResponse
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel, Field
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    raise ImportError("FastAPIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install fastapi uvicorn")

from db_utils import BungoDatabase
from gpt_relevance_service import GPTRelevanceService, RelevanceRequest
from export_geojson import GeoJSONExporter
from export_csv import CSVExporter, export_db_to_csv
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI appåˆæœŸåŒ–
app = FastAPI(
    title="æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  API",
    description="""
æ–‡è±ªãƒ»ä½œå“ãƒ»èˆå°ï¼ˆåœ°åï¼‰ã®3éšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã—ã€
æ¤œç´¢ãƒ»å¯è¦–åŒ–ãƒ»GPTé–¢é€£åº¦åˆ¤å®šæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹REST API

**ä¸»è¦æ©Ÿèƒ½:**
- ä½œè€…ãƒ»ä½œå“ãƒ»åœ°åã®æ¤œç´¢
- ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- GPTé–¢é€£åº¦åˆ¤å®šï¼ˆrelevanceâ‰¥0.8ã®ã¿å¯è¦–åŒ–ï¼‰
- ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """,
    version="1.0.0",
    contact={
        "name": "Bungo Map System",
        "email": "bungo-map@example.com"
    },
    license_info={
        "name": "MIT",
        "url": "https://opensource.org/licenses/MIT"
    }
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯åˆ¶é™ã™ã‚‹ã“ã¨
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¾å­˜é–¢ä¿‚
DATABASE_PATH = os.getenv('BUNGO_DB_PATH', 'test_ginza.db')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

def get_database() -> BungoDatabase:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
    return BungoDatabase("sqlite", DATABASE_PATH)

def get_gpt_service() -> GPTRelevanceService:
    """GPTé–¢é€£åº¦åˆ¤å®šã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    return GPTRelevanceService(OPENAI_API_KEY)

# Pydantic ãƒ¢ãƒ‡ãƒ«å®šç¾©

class ErrorResponse(BaseModel):
    error: Dict[str, str] = Field(..., description="ã‚¨ãƒ©ãƒ¼æƒ…å ±")

class HealthResponse(BaseModel):
    status: str = Field(..., description="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
    timestamp: datetime = Field(..., description="ãƒã‚§ãƒƒã‚¯æ™‚åˆ»")
    version: str = Field(..., description="ãƒãƒ¼ã‚¸ãƒ§ãƒ³")

class AuthorSearchResponse(BaseModel):
    authors: List[Dict[str, Any]] = Field(..., description="æ¤œç´¢ã•ã‚ŒãŸä½œè€…ä¸€è¦§")
    works: List[Dict[str, Any]] = Field(..., description="è©²å½“ä½œè€…ã®ä½œå“ä¸€è¦§")
    execution_time: float = Field(..., description="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰")
    total_count: int = Field(..., description="ç·ãƒ’ãƒƒãƒˆæ•°")

class WorkSearchResponse(BaseModel):
    works: List[Dict[str, Any]] = Field(..., description="æ¤œç´¢ã•ã‚ŒãŸä½œå“ä¸€è¦§")
    places: List[Dict[str, Any]] = Field(..., description="è©²å½“ä½œå“ã®åœ°åä¸€è¦§")
    execution_time: float = Field(..., description="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰")
    total_count: int = Field(..., description="ç·ãƒ’ãƒƒãƒˆæ•°")

class PlaceSearchResponse(BaseModel):
    places: List[Dict[str, Any]] = Field(..., description="æ¤œç´¢ã•ã‚ŒãŸåœ°åä¸€è¦§")
    authors: List[str] = Field(..., description="é–¢é€£ä½œè€…ä¸€è¦§")
    works: List[Dict[str, str]] = Field(..., description="é–¢é€£ä½œå“ä¸€è¦§")
    execution_time: float = Field(..., description="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰")
    total_count: int = Field(..., description="ç·ãƒ’ãƒƒãƒˆæ•°")

class PlaceListResponse(BaseModel):
    places: List[Dict[str, Any]] = Field(..., description="åœ°åä¸€è¦§")
    pagination: Dict[str, Any] = Field(..., description="ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")

class RelevanceRequestModel(BaseModel):
    place_name: str = Field(..., description="åœ°å")
    sentence: str = Field(..., description="è©²å½“æ–‡")
    work_title: str = Field(..., description="ä½œå“ã‚¿ã‚¤ãƒˆãƒ«")
    author_name: str = Field(..., description="ä½œè€…å")
    context: Optional[str] = Field(None, description="è¿½åŠ æ–‡è„ˆ")

class RelevanceResponseModel(BaseModel):
    relevance_score: float = Field(..., description="é–¢é€£åº¦ã‚¹ã‚³ã‚¢")
    is_relevant: bool = Field(..., description="é–¾å€¤ï¼ˆ0.8ï¼‰ä»¥ä¸Šã‹")
    reasoning: str = Field(..., description="åˆ¤å®šç†ç”±")
    execution_time: float = Field(..., description="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰")

class BatchRelevanceRequest(BaseModel):
    items: List[RelevanceRequestModel] = Field(..., max_items=100, description="ä¸€æ‹¬åˆ¤å®šå¯¾è±¡")

class BatchRelevanceResponse(BaseModel):
    results: List[Dict[str, Any]] = Field(..., description="åˆ¤å®šçµæœä¸€è¦§")
    total_count: int = Field(..., description="ç·ä»¶æ•°")
    relevant_count: int = Field(..., description="é–¢é€£åº¦â‰¥0.8ã®ä»¶æ•°")
    execution_time: float = Field(..., description="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰")

class StatsResponse(BaseModel):
    authors_count: int = Field(..., description="ä½œè€…æ•°")
    works_count: int = Field(..., description="ä½œå“æ•°")
    places_count: int = Field(..., description="åœ°åæ•°")
    geocoded_count: int = Field(..., description="ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿åœ°åæ•°")
    geocoded_rate: float = Field(..., description="ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‡ï¼ˆ%ï¼‰")
    relevant_places_count: Optional[int] = Field(None, description="é–¢é€£åº¦â‰¥0.8ã®åœ°åæ•°")
    last_updated: datetime = Field(..., description="æœ€çµ‚æ›´æ–°æ—¥æ™‚")

# =====================================
# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
# =====================================

@app.get("/health", response_model=HealthResponse, tags=["Admin"])
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return HealthResponse(
        status="ok",
        timestamp=datetime.now(),
        version="1.0.0"
    )

@app.get("/stats", response_model=StatsResponse, tags=["Admin"])
async def get_stats(db: BungoDatabase = Depends(get_database)):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆå–å¾—"""
    try:
        stats = db.get_stats()
        db.close()
        
        return StatsResponse(
            authors_count=stats.get('authors_count', 0),
            works_count=stats.get('works_count', 0),
            places_count=stats.get('places_count', 0),
            geocoded_count=stats.get('geocoded_count', 0),
            geocoded_rate=stats.get('geocoded_rate', 0.0),
            last_updated=datetime.now()
        )
    except Exception as e:
        db.close()
        logger.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "STATS_ERROR", "message": str(e)}})

# =====================================
# æ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================================

@app.get("/search/authors", response_model=AuthorSearchResponse, tags=["Search"])
async def search_authors(
    q: str = Query(..., description="æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆä½œè€…åï¼‰", min_length=1, max_length=100),
    limit: int = Query(10, description="æœ€å¤§çµæœæ•°", ge=1, le=100),
    include_works: bool = Query(True, description="ä½œå“ä¸€è¦§ã‚’å«ã‚€ã‹"),
    db: BungoDatabase = Depends(get_database)
):
    """ä½œè€…æ¤œç´¢"""
    try:
        start_time = time.time()
        
        # ä½œè€…æ¤œç´¢
        authors = db.search_authors(q)[:limit]
        
        # ä½œå“ä¸€è¦§å–å¾—
        works = []
        if include_works:
            for author in authors:
                author_works = db.search_works("")  # å…¨ä½œå“å–å¾—
                works.extend([w for w in author_works if w.get('author_name') == author['name']])
        
        execution_time = time.time() - start_time
        db.close()
        
        return AuthorSearchResponse(
            authors=authors,
            works=works[:limit * 3],  # ä½œå“ã¯å¤šã‚ã«è¡¨ç¤º
            execution_time=execution_time,
            total_count=len(authors)
        )
    except Exception as e:
        db.close()
        logger.error(f"ä½œè€…æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "SEARCH_ERROR", "message": str(e)}})

@app.get("/search/works", response_model=WorkSearchResponse, tags=["Search"])
async def search_works(
    q: str = Query(..., description="æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆä½œå“åï¼‰", min_length=1, max_length=100),
    limit: int = Query(10, description="æœ€å¤§çµæœæ•°", ge=1, le=100),
    include_places: bool = Query(True, description="åœ°åä¸€è¦§ã‚’å«ã‚€ã‹"),
    db: BungoDatabase = Depends(get_database)
):
    """ä½œå“æ¤œç´¢"""
    try:
        start_time = time.time()
        
        # ä½œå“æ¤œç´¢
        works = db.search_works(q)[:limit]
        
        # åœ°åä¸€è¦§å–å¾—
        places = []
        if include_places:
            for work in works:
                work_places = db.search_places("")  # å…¨åœ°åå–å¾—
                places.extend([p for p in work_places if p.get('work_title') == work['title']])
        
        execution_time = time.time() - start_time
        db.close()
        
        return WorkSearchResponse(
            works=works,
            places=places[:limit * 5],  # åœ°åã¯å¤šã‚ã«è¡¨ç¤º
            execution_time=execution_time,
            total_count=len(works)
        )
    except Exception as e:
        db.close()
        logger.error(f"ä½œå“æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "SEARCH_ERROR", "message": str(e)}})

@app.get("/search/places", response_model=PlaceSearchResponse, tags=["Search"])
async def search_places(
    q: str = Query(..., description="æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆåœ°åï¼‰", min_length=1, max_length=100),
    limit: int = Query(10, description="æœ€å¤§çµæœæ•°", ge=1, le=100),
    include_reverse: bool = Query(True, description="ä½œè€…ãƒ»ä½œå“é€†å¼•ãã‚’å«ã‚€ã‹"),
    db: BungoDatabase = Depends(get_database)
):
    """åœ°åæ¤œç´¢"""
    try:
        start_time = time.time()
        
        # åœ°åæ¤œç´¢
        places = db.search_places(q)[:limit]
        
        # é–¢é€£ä½œè€…ãƒ»ä½œå“ã®é€†å¼•ã
        authors = set()
        works = set()
        
        if include_reverse:
            for place in places:
                if place.get('author_name'):
                    authors.add(place['author_name'])
                if place.get('work_title'):
                    works.add((place.get('author_name'), place['work_title']))
        
        execution_time = time.time() - start_time
        db.close()
        
        return PlaceSearchResponse(
            places=places,
            authors=list(authors),
            works=[{'author_name': author, 'title': work} for author, work in works],
            execution_time=execution_time,
            total_count=len(places)
        )
    except Exception as e:
        db.close()
        logger.error(f"åœ°åæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "SEARCH_ERROR", "message": str(e)}})

# =====================================
# åœ°åè©³ç´°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================================

@app.get("/places", response_model=PlaceListResponse, tags=["Places"])
async def get_places(
    author: Optional[str] = Query(None, description="ä½œè€…åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    work: Optional[str] = Query(None, description="ä½œå“åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    geocoded_only: bool = Query(False, description="ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ã®ã¿"),
    limit: int = Query(100, description="æœ€å¤§çµæœæ•°", ge=1, le=1000),
    offset: int = Query(0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ", ge=0),
    db: BungoDatabase = Depends(get_database)
):
    """åœ°åä¸€è¦§å–å¾—"""
    try:
        # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«å¿œã˜ã¦æ¤œç´¢
        all_places = db.search_places("")  # å…¨åœ°åå–å¾—
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_places = all_places
        
        if author:
            filtered_places = [p for p in filtered_places if author.lower() in p.get('author_name', '').lower()]
        
        if work:
            filtered_places = [p for p in filtered_places if work.lower() in p.get('work_title', '').lower()]
        
        if geocoded_only:
            filtered_places = [p for p in filtered_places if p.get('latitude') and p.get('longitude')]
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total = len(filtered_places)
        places = filtered_places[offset:offset + limit]
        
        db.close()
        
        return PlaceListResponse(
            places=places,
            pagination={
                "total": total,
                "limit": limit,
                "offset": offset,
                "has_more": offset + limit < total
            }
        )
    except Exception as e:
        db.close()
        logger.error(f"åœ°åä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "PLACES_ERROR", "message": str(e)}})

@app.get("/places/{place_id}", tags=["Places"])
async def get_place_detail(
    place_id: int = Path(..., description="åœ°åID"),
    db: BungoDatabase = Depends(get_database)
):
    """åœ°åè©³ç´°å–å¾—"""
    try:
        # åœ°åè©³ç´°å–å¾—ï¼ˆå®Ÿè£…ã¯ç°¡ç•¥åŒ–ï¼‰
        places = db.search_places("")
        place = next((p for p in places if p.get('place_id') == place_id), None)
        
        db.close()
        
        if not place:
            raise HTTPException(status_code=404, detail={"error": {"code": "NOT_FOUND", "message": "åœ°åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}})
        
        return place
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        logger.error(f"åœ°åè©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "PLACE_ERROR", "message": str(e)}})

# =====================================
# GPTé–¢é€£åº¦åˆ¤å®šã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================================

@app.post("/gpt/relevance", response_model=RelevanceResponseModel, tags=["GPT"])
async def judge_relevance(
    request: RelevanceRequestModel = Body(...),
    gpt_service: GPTRelevanceService = Depends(get_gpt_service)
):
    """GPTé–¢é€£åº¦åˆ¤å®š"""
    try:
        relevance_req = RelevanceRequest(
            place_name=request.place_name,
            sentence=request.sentence,
            work_title=request.work_title,
            author_name=request.author_name,
            context=request.context
        )
        
        response = gpt_service.judge_relevance(relevance_req)
        
        return RelevanceResponseModel(
            relevance_score=response.relevance_score,
            is_relevant=response.is_relevant,
            reasoning=response.reasoning,
            execution_time=response.execution_time
        )
    except Exception as e:
        logger.error(f"GPTé–¢é€£åº¦åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "GPT_ERROR", "message": str(e)}})

@app.post("/gpt/batch-relevance", response_model=BatchRelevanceResponse, tags=["GPT"])
async def judge_relevance_batch(
    request: BatchRelevanceRequest = Body(...),
    gpt_service: GPTRelevanceService = Depends(get_gpt_service)
):
    """GPTé–¢é€£åº¦ä¸€æ‹¬åˆ¤å®š"""
    try:
        start_time = time.time()
        
        relevance_requests = [
            RelevanceRequest(
                place_name=item.place_name,
                sentence=item.sentence,
                work_title=item.work_title,
                author_name=item.author_name,
                context=item.context
            )
            for item in request.items
        ]
        
        responses = gpt_service.judge_relevance_batch(relevance_requests)
        
        results = []
        for i, response in enumerate(responses):
            results.append({
                "index": i,
                "relevance_score": response.relevance_score,
                "is_relevant": response.is_relevant,
                "reasoning": response.reasoning,
                "execution_time": response.execution_time
            })
        
        relevant_count = sum(1 for r in responses if r.is_relevant)
        total_time = time.time() - start_time
        
        return BatchRelevanceResponse(
            results=results,
            total_count=len(results),
            relevant_count=relevant_count,
            execution_time=total_time
        )
    except Exception as e:
        logger.error(f"GPTä¸€æ‹¬é–¢é€£åº¦åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "GPT_BATCH_ERROR", "message": str(e)}})

# =====================================
# GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# =====================================

@app.get("/export/geojson", tags=["Export"])
async def export_geojson(
    author: Optional[str] = Query(None, description="ä½œè€…åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    work: Optional[str] = Query(None, description="ä½œå“åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    relevance_threshold: float = Query(0.8, description="GPTé–¢é€£åº¦åˆ¤å®šã®é–¾å€¤", ge=0.0, le=1.0),
    db: BungoDatabase = Depends(get_database)
):
    """GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        # GeoJSONExporterã‚’ä½¿ç”¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        exporter = GeoJSONExporter("output")
        output_path = exporter.export_from_database(db, "api_export.geojson")
        
        db.close()
        
        if not output_path or not os.path.exists(output_path):
            raise HTTPException(status_code=500, detail={"error": {"code": "EXPORT_ERROR", "message": "GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"}})
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã‚“ã§JSONã¨ã—ã¦è¿”ã™
        with open(output_path, 'r', encoding='utf-8') as f:
            geojson_data = json.load(f)
        
        # application/geo+json ã§è¿”ã™
        return JSONResponse(content=geojson_data, media_type="application/geo+json")
        
    except Exception as e:
        logger.error(f"GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "EXPORT_ERROR", "message": str(e)}})

# =====================================
# CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# =====================================

@app.get("/export/csv", tags=["Export"])
async def export_csv(
    export_type: str = Query("combined", description="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç¨®åˆ¥", regex="^(all|authors|works|places|combined)$"),
    author: Optional[str] = Query(None, description="ä½œè€…åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    work: Optional[str] = Query(None, description="ä½œå“åã§ãƒ•ã‚£ãƒ«ã‚¿"),
    geocoded_only: bool = Query(False, description="ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ã®ã¿ï¼ˆplacesæ™‚ã®ã¿ï¼‰"),
    db: BungoDatabase = Depends(get_database)
):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…å®¹ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        db.close()  # å…ˆã«DBã‚’é–‰ã˜ã‚‹
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
        results = export_db_to_csv(
            db_path=DATABASE_PATH,
            output_dir="output",
            export_type=export_type,
            author_filter=author,
            work_filter=work,
            geocoded_only=geocoded_only
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
        file_info = []
        for key, filepath in results.items():
            file_size = os.path.getsize(filepath)
            file_info.append({
                "export_type": key,
                "filename": os.path.basename(filepath),
                "filepath": filepath,
                "size_bytes": file_size,
                "size_kb": round(file_size / 1024, 2)
            })
        
        return {
            "message": "CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†",
            "export_type": export_type,
            "files": file_info,
            "filters": {
                "author": author,
                "work": work,
                "geocoded_only": geocoded_only
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "CSV_EXPORT_ERROR", "message": str(e)}})

@app.get("/export/csv/download/{filename}", tags=["Export"])
async def download_csv_file(filename: str = Path(..., description="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«å")):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        filepath = f"output/{filename}"
        
        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail={"error": {"code": "FILE_NOT_FOUND", "message": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}})
        
        from fastapi.responses import FileResponse
        
        return FileResponse(
            path=filepath,
            filename=filename,
            media_type="text/csv; charset=utf-8"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail={"error": {"code": "DOWNLOAD_ERROR", "message": str(e)}})

# =====================================
# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•é–¢æ•°
# =====================================

def run_server(host: str = "0.0.0.0", port: int = 8000, reload: bool = True):
    """API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•"""
    try:
        import uvicorn
        logger.info(f"ğŸš€ æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•: http://{host}:{port}")
        logger.info(f"ğŸ“– OpenAPI ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://{host}:{port}/docs")
        logger.info(f"ğŸ“Š ReDoc ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://{host}:{port}/redoc")
        
        uvicorn.run("api_server:app", host=host, port=port, reload=reload)
    except ImportError:
        logger.error("uvicorn ãŒå¿…è¦ã§ã™: pip install uvicorn")
        raise

if __name__ == "__main__":
    run_server() 