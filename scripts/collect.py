#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡è±ªåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ä»•æ§˜æ›¸ bungo_update_spec_draft01.md 4ç« ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ›´æ–°ãƒ•ãƒ­ãƒ¼ã«åŸºã¥ãå®Ÿè£…
"""

import argparse
import logging
import sys
import time
from typing import List, Dict, Optional

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from db_utils import BungoDatabase
    from aozora_utils import AozoraUtils
    from aozora_place_extract import AozoraPlaceExtractor
    from geocode_utils import GeocodeUtils
except ImportError as e:
    print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install -r requirements.txt")
    sys.exit(1)


class BungoDataCollector:
    """æ–‡è±ªãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self, db_path: str = "bungo_production.db"):
        self.logger = logging.getLogger(__name__)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.db = BungoDatabase("sqlite", db_path)
        
        # é’ç©ºæ–‡åº«ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        self.aozora = AozoraUtils()
        
        # åœ°åæŠ½å‡ºå™¨
        self.place_extractor = AozoraPlaceExtractor()
        
        # ã‚¸ã‚ªã‚³ãƒ¼ãƒ€ãƒ¼
        self.geocoder = GeocodeUtils()
        
        self.logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†: {db_path}")
    
    def collect_author_data(self, author_name: str, max_works: int = 5, geocode: bool = True) -> Dict:
        """
        ä½œè€…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬åé›†
        ä»•æ§˜æ›¸ Seq 1-7: Wikipediaâ†’works â†’ é’ç©ºæ–‡åº«â†’places â†’ ã‚¸ã‚ªã‚³ãƒ¼ãƒ‰
        
        Args:
            author_name: ä½œè€…å
            max_works: æœ€å¤§å–å¾—ä½œå“æ•°
            geocode: ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Ÿè¡Œãƒ•ãƒ©ã‚°
            
        Returns:
            åé›†çµæœçµ±è¨ˆ
        """
        self.logger.info(f"ğŸ“š {author_name}ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        
        stats = {
            'author_name': author_name,
            'authors_inserted': 0,
            'works_inserted': 0,
            'places_inserted': 0,
            'geocoded_count': 0,
            'errors': []
        }
        
        try:
            # Step 1: ä½œè€…ç™»éŒ²
            author_id = self.db.insert_author(author_name)
            if author_id:
                stats['authors_inserted'] = 1
                self.logger.info(f"âœ… ä½œè€…ç™»éŒ²: {author_name} (ID: {author_id})")
            
            # Step 2-4: é’ç©ºæ–‡åº«ã‹ã‚‰ä½œå“å–å¾—
            self.logger.info("ğŸ“¥ é’ç©ºæ–‡åº«ã‹ã‚‰ä½œå“å–å¾—ä¸­...")
            work_results = self.aozora.batch_download_works(author_name, max_works)
            
            # Step 2: ä½œå“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²
            for work_result in work_results:
                if work_result.get('success'):
                    work_id = self.db.insert_work(
                        author_id=author_id,
                        title=work_result['title'],
                        aozora_url=work_result.get('file_url'),
                        publication_year=None,  # é’ç©ºæ–‡åº«ã‹ã‚‰ã¯å–å¾—å›°é›£
                        genre=None
                    )
                    if work_id:
                        stats['works_inserted'] += 1
                        work_result['work_id'] = work_id
            
            # Step 5: GiNZAåœ°åæŠ½å‡º
            self.logger.info("ğŸ—ºï¸ GiNZAåœ°åæŠ½å‡ºä¸­...")
            all_places = self.place_extractor.batch_extract_from_works(work_results)
            
            # Step 6: åœ°åãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²
            for place_data in all_places:
                work_id = self._find_work_id(place_data, work_results)
                if work_id:
                    place_id = self.db.upsert_place(
                        work_id=work_id,
                        place_name=place_data['place_name'],
                        before_text=place_data.get('before_text', ''),
                        sentence=place_data.get('sentence', ''),
                        after_text=place_data.get('after_text', ''),
                        extraction_method=place_data.get('extraction_method', 'ginza'),
                        confidence=place_data.get('confidence', 0.8)
                    )
                    if place_id:
                        stats['places_inserted'] += 1
            
            # Step 7: ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if geocode and stats['places_inserted'] > 0:
                self.logger.info("ğŸ“ ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Ÿè¡Œä¸­...")
                geocode_stats = self.geocoder.update_database_places(self.db)
                stats['geocoded_count'] = geocode_stats.get('updated', 0)
            
            self.logger.info(f"âœ… {author_name}ã®ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
            
        except Exception as e:
            error_msg = f"âŒ ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}"
            self.logger.error(error_msg)
            stats['errors'].append(error_msg)
        
        return stats
    
    def _find_work_id(self, place_data: Dict, work_results: List[Dict]) -> Optional[int]:
        """åœ°åãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¯¾å¿œã™ã‚‹ä½œå“IDã‚’æ¤œç´¢"""
        author_name = place_data.get('author_name', '')
        work_title = place_data.get('work_title', '')
        
        for work_result in work_results:
            if (work_result.get('author_name') == author_name and 
                work_result.get('title') == work_title and
                work_result.get('work_id')):
                return work_result['work_id']
        
        return None
    
    def collect_multiple_authors(self, author_names: List[str], max_works: int = 5) -> Dict:
        """
        è¤‡æ•°ä½œè€…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬åé›†
        
        Args:
            author_names: ä½œè€…åãƒªã‚¹ãƒˆ
            max_works: ä½œè€…ã‚ãŸã‚Šã®æœ€å¤§ä½œå“æ•°
            
        Returns:
            å…¨ä½“ã®åé›†çµæœçµ±è¨ˆ
        """
        self.logger.info(f"ğŸ“š è¤‡æ•°ä½œè€…ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹: {len(author_names)}å")
        
        overall_stats = {
            'total_authors': len(author_names),
            'successful_authors': 0,
            'total_works': 0,
            'total_places': 0,
            'total_geocoded': 0,
            'author_details': []
        }
        
        for i, author_name in enumerate(author_names, 1):
            self.logger.info(f"== å‡¦ç†ä¸­ ({i}/{len(author_names)}): {author_name} ==")
            
            author_stats = self.collect_author_data(author_name, max_works, geocode=False)
            overall_stats['author_details'].append(author_stats)
            
            if not author_stats['errors']:
                overall_stats['successful_authors'] += 1
            
            overall_stats['total_works'] += author_stats['works_inserted']
            overall_stats['total_places'] += author_stats['places_inserted']
            
            # APIåˆ¶é™å¯¾ç­–
            time.sleep(3)
        
        # æœ€å¾Œã«ä¸€æ‹¬ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        if overall_stats['total_places'] > 0:
            self.logger.info("ğŸ“ ä¸€æ‹¬ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Ÿè¡Œä¸­...")
            geocode_stats = self.geocoder.update_database_places(self.db)
            overall_stats['total_geocoded'] = geocode_stats.get('updated', 0)
        
        self.logger.info("âœ… è¤‡æ•°ä½œè€…ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
        return overall_stats
    
    def test_pipeline(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        self.logger.info("ğŸ§ª ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ
        test_stats = self.collect_author_data("å¤ç›®æ¼±çŸ³", max_works=1, geocode=True)
        
        success = (
            test_stats['authors_inserted'] > 0 and
            test_stats['works_inserted'] > 0 and 
            len(test_stats['errors']) == 0
        )
        
        if success:
            self.logger.info("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆæˆåŠŸ")
        else:
            self.logger.error("âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå¤±æ•—")
        
        return success
    
    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.db.close()


def main():
    """ãƒ¡ã‚¤ãƒ³CLIé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='æ–‡è±ªåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å˜ä¸€ä½œè€…ã®ä½œå“åé›†
  python collect.py --author "å¤ç›®æ¼±çŸ³" --max-works 3

  # è¤‡æ•°ä½œè€…ã®ä¸€æ‹¬åé›†
  python collect.py --all --max-works 5

  # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
  python collect.py --test

ä¸»è¦æ©Ÿèƒ½:
  1. Wikipedia/é’ç©ºæ–‡åº«ã‹ã‚‰ä½œå“ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
  2. GiNZA NERã«ã‚ˆã‚‹åœ°åæŠ½å‡ºï¼ˆå‰å¾Œæ–‡ä»˜ãï¼‰
  3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²ãƒ»ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        """
    )
    
    parser.add_argument('--author', help='ä½œè€…åã‚’æŒ‡å®š')
    parser.add_argument('--all', action='store_true', help='ä¸»è¦ä½œå®¶å…¨å“¡ã‚’åé›†')
    parser.add_argument('--max-works', type=int, default=5, help='æœ€å¤§å–å¾—ä½œå“æ•°')
    parser.add_argument('--db-path', default='bungo_production.db', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹')
    parser.add_argument('--no-geocode', action='store_true', help='ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ')
    parser.add_argument('--title', help='ç‰¹å®šã®ä½œå“ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŒ‡å®š')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(f'collect_{int(time.time())}.log')
        ]
    )
    
    # ãƒ‡ãƒ¼ã‚¿åé›†å™¨åˆæœŸåŒ–
    try:
        collector = BungoDataCollector(args.db_path)
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    try:
        if args.test:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
            success = collector.test_pipeline()
            return 0 if success else 1
        
        elif args.author:
            # å˜ä¸€ä½œè€…åé›†
            stats = collector.collect_author_data(
                args.author, 
                args.max_works, 
                geocode=not args.no_geocode
            )
            
            print(f"\nğŸ“Š åé›†çµæœ: {args.author}")
            print(f"   ä½œè€…ç™»éŒ²: {stats['authors_inserted']}")
            print(f"   ä½œå“ç™»éŒ²: {stats['works_inserted']}")
            print(f"   åœ°åç™»éŒ²: {stats['places_inserted']}")
            print(f"   ã‚¸ã‚ªã‚³ãƒ¼ãƒ‰: {stats['geocoded_count']}")
            
            if stats['errors']:
                print(f"   ã‚¨ãƒ©ãƒ¼: {len(stats['errors'])}ä»¶")
                for error in stats['errors']:
                    print(f"     - {error}")
        
        elif args.all:
            # è¤‡æ•°ä½œè€…ä¸€æ‹¬åé›†
            major_authors = [
                "å¤ç›®æ¼±çŸ³", "èŠ¥å·é¾ä¹‹ä»‹", "å¤ªå®°æ²»", "å·ç«¯åº·æˆ", "å®®æ²¢è³¢æ²»",
                "æ£®é´å¤–", "æ¨‹å£ä¸€è‘‰", "çŸ³å·å•„æœ¨", "ä¸è¬é‡æ™¶å­", "æ­£å²¡å­è¦"
            ]
            
            stats = collector.collect_multiple_authors(major_authors, args.max_works)
            
            print(f"\nğŸ“Š ä¸€æ‹¬åé›†çµæœ:")
            print(f"   å¯¾è±¡ä½œè€…: {stats['total_authors']}å")
            print(f"   æˆåŠŸä½œè€…: {stats['successful_authors']}å")
            print(f"   ç·ä½œå“æ•°: {stats['total_works']}")
            print(f"   ç·åœ°åæ•°: {stats['total_places']}")
            print(f"   ã‚¸ã‚ªã‚³ãƒ¼ãƒ‰: {stats['total_geocoded']}")
        
        else:
            parser.print_help()
            return 1
    
    except KeyboardInterrupt:
        print("\nâš ï¸ å‡¦ç†ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 130
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1
    finally:
        collector.close()
    
    return 0


if __name__ == "__main__":
    sys.exit(main()) 