#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é’ç©ºæ–‡åº«å®Ÿç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
ä»•æ§˜æ›¸ bungo_update_spec_draft01.md S2ç«  é’ç©ºæ–‡åº«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«åŸºã¥ãå®Ÿè£…

å®Ÿéš›ã®é’ç©ºæ–‡åº«HTMLãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
"""

import requests
import re
import time
import os
from typing import Dict, List, Optional, Tuple
import logging
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AozoraPracticalClient:
    """é’ç©ºæ–‡åº«å®Ÿç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆHTMLè§£æç‰ˆï¼‰"""
    
    def __init__(self, cache_dir: str = "aozora_cache"):
        self.base_url = "https://www.aozora.gr.jp"
        self.cache_dir = cache_dir
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (BungoMapSystem/1.0) Educational Research'
        })
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(cache_dir, exist_ok=True)
        
        # æ—¢çŸ¥ã®ä½œå“IDè¾æ›¸ï¼ˆæ‰‹å‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        self.known_works = {
            'å¤ç›®æ¼±çŸ³': {
                'åŠã£ã¡ã‚ƒã‚“': ('000148', 'files/752_14964.html'),
                'å¾è¼©ã¯çŒ«ã§ã‚ã‚‹': ('000148', 'files/789_14547.html'),
                'ã“ã“ã‚': ('000148', 'files/773_14560.html'),
                'ä¸‰å››éƒ': ('000148', 'files/794_14972.html'),
                'ãã‚Œã‹ã‚‰': ('000148', 'files/795_15005.html')
            },
            'èŠ¥å·é¾ä¹‹ä»‹': {
                'ç¾…ç”Ÿé–€': ('000879', 'files/127_15260.html'),
                'èœ˜è››ã®ç³¸': ('000879', 'files/92_2689.html'),
                'é¼»': ('000879', 'files/42_375.html'),
                'åœ°ç„å¤‰': ('000879', 'files/1869_6257.html')
            },
            'å¤ªå®°æ²»': {
                'äººé–“å¤±æ ¼': ('000035', 'files/301_14912.html'),
                'èµ°ã‚Œãƒ¡ãƒ­ã‚¹': ('000035', 'files/1567_4948.html'),
                'æ´¥è»½': ('000035', 'files/570_8243.html')
            },
            'å·ç«¯åº·æˆ': {
                'é›ªå›½': ('000084', 'files/1235_8303.html'),
                'ä¼Šè±†ã®è¸Šå­': ('000084', 'files/45_362.html')
            },
            'å®®æ²¢è³¢æ²»': {
                'éŠ€æ²³é‰„é“ã®å¤œ': ('000081', 'files/456_15050.html'),
                'æ³¨æ–‡ã®å¤šã„æ–™ç†åº—': ('000081', 'files/1927_6925.html'),
                'ã‚»ãƒ­å¼¾ãã®ã‚´ãƒ¼ã‚·ãƒ¥': ('000081', 'files/470_15407.html')
            }
        }
    
    def get_work_url(self, author: str, title: str) -> Optional[str]:
        """æ—¢çŸ¥ä½œå“ã®URLå–å¾—"""
        if author in self.known_works and title in self.known_works[author]:
            author_id, file_path = self.known_works[author][title]
            url = f"{self.base_url}/cards/{author_id}/{file_path}"
            return url
        return None
    
    def fetch_text_from_html(self, url: str) -> Optional[str]:
        """HTMLãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
        try:
            self.logger.info(f"HTMLãƒ†ã‚­ã‚¹ãƒˆå–å¾—: {url}")
            response = self.session.get(url, timeout=15)
            
            if response.status_code != 200:
                self.logger.warning(f"HTTPå–å¾—å¤±æ•—: {response.status_code}")
                return None
            
            # Shift_JISã§ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆé’ç©ºæ–‡åº«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            try:
                html_content = response.content.decode('shift_jis')
            except UnicodeDecodeError:
                html_content = response.content.decode('utf-8', errors='ignore')
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æœ¬æ–‡æŠ½å‡ºï¼ˆé’ç©ºæ–‡åº«HTMLæ§‹é€ ã«åŸºã¥ãï¼‰
            # main_textã‚¯ãƒ©ã‚¹ã¾ãŸã¯div.main_textã‚’æ¢ã™
            main_text = soup.find('div', class_='main_text')
            if not main_text:
                # bodyã®ä¸­ã‹ã‚‰æœ¬æ–‡ã‚‰ã—ã„éƒ¨åˆ†ã‚’æŠ½å‡º
                body = soup.find('body')
                if body:
                    # scriptã¨styleã‚¿ã‚°ã‚’é™¤å»
                    for tag in body(['script', 'style', 'nav', 'header', 'footer']):
                        tag.decompose()
                    main_text = body
            
            if main_text:
                # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                text = main_text.get_text()
                # é’ç©ºæ–‡åº«ç‰¹æœ‰ã®æ³¨è¨˜ã‚’é™¤å»
                text = re.sub(r'ï¼»ï¼ƒ[^ï¼½]*ï¼½', '', text)  # ãƒ«ãƒ“ç­‰ã®æ³¨è¨˜é™¤å»
                text = re.sub(r'\s+', ' ', text)  # ç©ºç™½æ­£è¦åŒ–
                text = text.strip()
                
                self.logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºæˆåŠŸ: {len(text)}æ–‡å­—")
                return text
            else:
                self.logger.warning("æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
                
        except Exception as e:
            self.logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def cache_text(self, cache_key: str, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
        cache_file = Path(self.cache_dir) / f"{cache_key}.txt"
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                f.write(text)
            self.logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {cache_file}")
            return str(cache_file)
        except Exception as e:
            self.logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def load_cached_text(self, cache_key: str) -> Optional[str]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿"""
        cache_file = Path(self.cache_dir) / f"{cache_key}.txt"
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    text = f.read()
                self.logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿: {cache_file}")
                return text
            except Exception as e:
                self.logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    def fetch_work(self, author: str, title: str) -> Optional[Dict]:
        """ä½œå“å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
        cache_key = f"{author}_{title}".replace(" ", "_")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        cached_text = self.load_cached_text(cache_key)
        if cached_text:
            return {
                'author': author,
                'title': title,
                'text': cached_text,
                'cache_hit': True,
                'source': 'cache'
            }
        
        # URLã‚’å–å¾—
        url = self.get_work_url(author, title)
        if not url:
            self.logger.warning(f"æœªå¯¾å¿œä½œå“: {author} - {title}")
            return None
        
        # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        text = self.fetch_text_from_html(url)
        if text:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            self.cache_text(cache_key, text)
            time.sleep(2)  # ã‚µã‚¤ãƒˆè² è·è»½æ¸›
            
            return {
                'author': author,
                'title': title,
                'text': text,
                'cache_hit': False,
                'source': 'web',
                'url': url
            }
        
        return None
    
    def list_available_works(self) -> Dict[str, List[str]]:
        """åˆ©ç”¨å¯èƒ½ä½œå“ãƒªã‚¹ãƒˆ"""
        return {author: list(works.keys()) for author, works in self.known_works.items()}

def test_practical_client():
    """å®Ÿç”¨é’ç©ºæ–‡åº«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª é’ç©ºæ–‡åº«å®Ÿç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    client = AozoraPracticalClient()
    
    # åˆ©ç”¨å¯èƒ½ä½œå“è¡¨ç¤º
    print("\nğŸ“š åˆ©ç”¨å¯èƒ½ä½œå“ä¸€è¦§:")
    available = client.list_available_works()
    for author, works in available.items():
        print(f"  {author}: {', '.join(works[:3])}{'...' if len(works) > 3 else ''}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: åŠã£ã¡ã‚ƒã‚“å–å¾—
    print("\nğŸ“– ãƒ†ã‚¹ãƒˆ1: å¤ç›®æ¼±çŸ³ã€åŠã£ã¡ã‚ƒã‚“ã€å–å¾—")
    work = client.fetch_work("å¤ç›®æ¼±çŸ³", "åŠã£ã¡ã‚ƒã‚“")
    if work:
        text = work['text']
        print(f"âœ… å–å¾—æˆåŠŸ: {work['title']} ({len(text)}æ–‡å­—)")
        print(f"ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {'ãƒ’ãƒƒãƒˆ' if work['cache_hit'] else 'ãƒŸã‚¹'}")
        print(f"ğŸŒ ã‚½ãƒ¼ã‚¹: {work['source']}")
        print(f"ğŸ“ å†’é ­: {text[:150]}...")
    else:
        print("âŒ å–å¾—å¤±æ•—")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: ç¾…ç”Ÿé–€å–å¾—
    print("\nğŸ“– ãƒ†ã‚¹ãƒˆ2: èŠ¥å·é¾ä¹‹ä»‹ã€ç¾…ç”Ÿé–€ã€å–å¾—")
    work = client.fetch_work("èŠ¥å·é¾ä¹‹ä»‹", "ç¾…ç”Ÿé–€")
    if work:
        text = work['text']
        print(f"âœ… å–å¾—æˆåŠŸ: {work['title']} ({len(text)}æ–‡å­—)")
        print(f"ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {'ãƒ’ãƒƒãƒˆ' if work['cache_hit'] else 'ãƒŸã‚¹'}")
        print(f"ğŸ“ å†’é ­: {text[:150]}...")
    else:
        print("âŒ å–å¾—å¤±æ•—")
    
    print("\nğŸ¯ é’ç©ºæ–‡åº«å®Ÿç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_practical_client() 