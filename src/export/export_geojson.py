#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
ä»•æ§˜æ›¸ bungo_update_spec_draft01.md 5ç« ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã«åŸºã¥ãå®Ÿè£…
"""

import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd


class GeoJSONExporter:
    """GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    def __init__(self, output_dir: str = "output"):
        """
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.output_dir = output_dir
        self.logger = logging.getLogger(__name__)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
    
    def export_from_database(self, db, output_filename: str = "bungo_places.geojson") -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            db: BungoDatabaseã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            output_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨åœ°åãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        df = self._get_places_dataframe(db)
        
        if df.empty:
            self.logger.warning("âš ï¸ åœ°åãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        # GeoJSONç”Ÿæˆ
        geojson = self._create_geojson(df)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        output_path = os.path.join(self.output_dir, output_filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(geojson, f, ensure_ascii=False, indent=2)
        
        # çµ±è¨ˆæƒ…å ±ãƒ­ã‚°
        total_places = len(df)
        geocoded_places = len(df[df['latitude'].notna() & df['longitude'].notna()])
        geocoded_rate = geocoded_places / total_places * 100 if total_places > 0 else 0
        
        self.logger.info(f"âœ… GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}")
        self.logger.info(f"   ç·åœ°åæ•°: {total_places}")
        self.logger.info(f"   ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿: {geocoded_places} ({geocoded_rate:.1f}%)")
        
        return output_path
    
    def _get_places_dataframe(self, db) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰åœ°åãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—"""
        if hasattr(db, 'conn'):  # SQLite
            query = """
            SELECT 
                p.place_id,
                p.work_id,
                p.place_name,
                p.latitude,
                p.longitude,
                p.address,
                p.before_text,
                p.sentence,
                p.after_text,
                p.extraction_method,
                p.confidence,
                p.maps_url,
                p.geocoded,
                w.title as work_title,
                w.aozora_url,
                w.wikipedia_url as work_wikipedia_url,
                a.name as author_name,
                a.wikipedia_url as author_wikipedia_url
            FROM places p
            JOIN works w ON p.work_id = w.work_id
            JOIN authors a ON w.author_id = a.author_id
            WHERE p.latitude IS NOT NULL AND p.longitude IS NOT NULL
            ORDER BY a.name, w.title, p.place_name
            """
            return pd.read_sql_query(query, db.conn)
        else:
            raise NotImplementedError("Google Sheetsã‹ã‚‰ã®GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¯æœªå®Ÿè£…")
    
    def _create_geojson(self, df: pd.DataFrame) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰GeoJSONå½¢å¼ã‚’ç”Ÿæˆ"""
        features = []
        
        for _, row in df.iterrows():
            # MapKitç”¨ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£è¨­è¨ˆ
            properties = {
                # åŸºæœ¬æƒ…å ±
                "place_id": int(row['place_id']) if pd.notna(row['place_id']) else None,
                "place_name": row['place_name'],
                "author_name": row['author_name'],
                "work_title": row['work_title'],
                
                # åœ°ç†æƒ…å ±
                "address": row['address'] if pd.notna(row['address']) else None,
                "maps_url": row['maps_url'] if pd.notna(row['maps_url']) else None,
                
                # æ–‡è„ˆæƒ…å ±ï¼ˆMapKit ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
                "before_text": row['before_text'] if pd.notna(row['before_text']) else "",
                "sentence": row['sentence'] if pd.notna(row['sentence']) else "",
                "after_text": row['after_text'] if pd.notna(row['after_text']) else "",
                "context": self._create_context_text(row),
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                "extraction_method": row['extraction_method'] if pd.notna(row['extraction_method']) else "unknown",
                "confidence": float(row['confidence']) if pd.notna(row['confidence']) else 0.0,
                "aozora_url": row['aozora_url'] if pd.notna(row['aozora_url']) else None,
                "work_wikipedia_url": row['work_wikipedia_url'] if pd.notna(row['work_wikipedia_url']) else None,
                "author_wikipedia_url": row['author_wikipedia_url'] if pd.notna(row['author_wikipedia_url']) else None,
                
                # è¡¨ç¤ºç”¨æƒ…å ±
                "title": f"{row['author_name']}ã€{row['work_title']}ã€",
                "subtitle": row['place_name'],
                "description": self._create_description(row)
            }
            
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [float(row['longitude']), float(row['latitude'])]  # GeoJSONã¯ [lng, lat] é †
                },
                "properties": properties
            }
            
            features.append(feature)
        
        # GeoJSONæ§‹é€ 
        geojson = {
            "type": "FeatureCollection",
            "metadata": {
                "generator": "bungo_places_exporter",
                "generated_at": datetime.now().isoformat(),
                "total_features": len(features),
                "authors": df['author_name'].nunique(),
                "works": df['work_title'].nunique(),
                "places": df['place_name'].nunique()
            },
            "features": features
        }
        
        return geojson
    
    def _create_context_text(self, row) -> str:
        """å‰å¾Œæ–‡ã‚’çµ„ã¿åˆã‚ã›ãŸæ–‡è„ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ"""
        parts = []
        
        if pd.notna(row['before_text']) and row['before_text'].strip():
            parts.append(row['before_text'].strip())
        
        if pd.notna(row['sentence']) and row['sentence'].strip():
            parts.append(f"ã€{row['sentence'].strip()}ã€‘")  # ãƒ¡ã‚¤ãƒ³æ–‡ã‚’å¼·èª¿
        
        if pd.notna(row['after_text']) and row['after_text'].strip():
            parts.append(row['after_text'].strip())
        
        return "".join(parts) if parts else ""
    
    def _create_description(self, row) -> str:
        """MapKit ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®èª¬æ˜æ–‡ã‚’ä½œæˆ"""
        desc_parts = []
        
        # ä½œå“æƒ…å ±
        desc_parts.append(f"ğŸ“š {row['author_name']}ã€{row['work_title']}ã€")
        
        # ä½æ‰€æƒ…å ±
        if pd.notna(row['address']):
            desc_parts.append(f"ğŸ“ {row['address']}")
        
        # æ–‡è„ˆæƒ…å ±ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        context = self._create_context_text(row)
        if context and len(context) > 0:
            # é•·ã™ãã‚‹å ´åˆã¯çœç•¥
            if len(context) > 100:
                context = context[:97] + "..."
            desc_parts.append(f"ğŸ’­ {context}")
        
        # ä¿¡é ¼åº¦æƒ…å ±
        if pd.notna(row['confidence']) and row['confidence'] > 0:
            desc_parts.append(f"ğŸ¯ ä¿¡é ¼åº¦: {row['confidence']:.1f}")
        
        return "\n".join(desc_parts)
    
    def export_summary_stats(self, db, output_filename: str = "bungo_stats.json") -> str:
        """
        çµ±è¨ˆæƒ…å ±ã‚’JSONã§å‡ºåŠ›
        
        Args:
            db: BungoDatabaseã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            output_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆå–å¾—
        stats = db.get_stats()
        
        # è¿½åŠ çµ±è¨ˆæƒ…å ±
        df = self._get_places_dataframe(db)
        
        extended_stats = {
            **stats,
            "export_stats": {
                "exportable_places": len(df),
                "top_authors": df['author_name'].value_counts().head(10).to_dict(),
                "top_places": df['place_name'].value_counts().head(10).to_dict(),
                "extraction_methods": df['extraction_method'].value_counts().to_dict(),
                "confidence_distribution": {
                    "high (>0.8)": len(df[df['confidence'] > 0.8]),
                    "medium (0.5-0.8)": len(df[(df['confidence'] >= 0.5) & (df['confidence'] <= 0.8)]),
                    "low (<0.5)": len(df[df['confidence'] < 0.5])
                }
            },
            "generated_at": datetime.now().isoformat()
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        output_path = os.path.join(self.output_dir, output_filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(extended_stats, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"âœ… çµ±è¨ˆæƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}")
        
        return output_path
    
    def export_csv_for_analysis(self, db, output_filename: str = "bungo_analysis.csv") -> str:
        """
        åˆ†æç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
        
        Args:
            db: BungoDatabaseã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            output_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        df = self._get_places_dataframe(db)
        
        if df.empty:
            self.logger.warning("âš ï¸ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # åˆ†æç”¨ã«åˆ—ã‚’æ•´ç†ï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ä½¿ç”¨ï¼‰
        available_cols = ['author_name', 'work_title', 'place_name', 'latitude', 'longitude', 
                         'address', 'extraction_method', 'confidence']
        analysis_df = df[[col for col in available_cols if col in df.columns]].copy()
        
        # æ–‡è„ˆåˆ—ã‚’è¿½åŠ 
        analysis_df['context'] = df.apply(self._create_context_text, axis=1)
        
        output_path = os.path.join(self.output_dir, output_filename)
        analysis_df.to_csv(output_path, index=False, encoding='utf-8')
        
        self.logger.info(f"âœ… åˆ†æç”¨CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}")
        self.logger.info(f"   ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(analysis_df)}")
        
        return output_path


def test_geojson_exporter():
    """GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    from db_utils import BungoDatabase
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    db = BungoDatabase("sqlite", "test_export.db")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
    author_id = db.insert_author("ãƒ†ã‚¹ãƒˆä½œå®¶", "https://example.com")
    work_id = db.insert_work(author_id, "ãƒ†ã‚¹ãƒˆä½œå“", "https://example.com")
    
    db.upsert_place(work_id, "æ±äº¬éƒ½", 35.6762, 139.6503, "æ±äº¬éƒ½, æ—¥æœ¬", 
                   "å‰æ–‡", "æœ¬æ–‡ã«æ±äº¬éƒ½ãŒç™»å ´", "å¾Œæ–‡", "test", 0.9)
    db.upsert_place(work_id, "å¤§é˜ªåºœ", 34.6937, 135.5023, "å¤§é˜ªåºœ, æ—¥æœ¬", 
                   "å‰æ–‡", "å¤§é˜ªåºœã®æå†™", "å¾Œæ–‡", "test", 0.8)
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
    exporter = GeoJSONExporter("test_output")
    
    print("ğŸ§ª GeoJSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    geojson_path = exporter.export_from_database(db, "test_bungo.geojson")
    print(f"   GeoJSONå‡ºåŠ›: {geojson_path}")
    
    stats_path = exporter.export_summary_stats(db, "test_stats.json")
    print(f"   çµ±è¨ˆæƒ…å ±å‡ºåŠ›: {stats_path}")
    
    csv_path = exporter.export_csv_for_analysis(db, "test_analysis.csv")
    print(f"   CSVå‡ºåŠ›: {csv_path}")
    
    db.close()


if __name__ == "__main__":
    test_geojson_exporter() 